/*
 ============================================================================
 Name        : mpiParallelOP.c
 Author      : at
 Supervisor  : Prof. Dr. Martin Theobald
 Version     : 6.0
 Copyright   : University of Luxembourg
 Description : Map and Reduce Simulation using MPI
 ============================================================================
 */

#include <mpi.h>
#include <math.h>
#include <iostream>
#include <fstream>
#include <time.h>
#include <stdlib.h>
#include <stdio.h>
#include <pthread.h>
#include <unistd.h>

using namespace std;
static long sentByNPerSec, sent;
static long receivedByNPerSec, received;
int slaveNode = 0;
//Data load integers (size = 4 bytes)

class MpiParallelOp{
protected:
	//number of integers
	int numberOfElements;
	int sizeOfElement;
	//Number of slave nodes
	int n;
	//Size of partitions
	int shardsLength1;
	int shardsLength2;
	int dominantCount;
	int lastPartitionCount;
	int fileLength;

public:
	MpiParallelOp();
	MpiParallelOp(int, int);

	////////////////////////////////////
	//Getting the data
	///////////////////////////////////
protected:
	char * getBinaryData(){

		/*ofstream dataSource;
		srand(time(NULL));
		int counter = 1;
		dataSource.open("../dataInt.bin", ios::binary | ios::out);
		while(counter <= numberOfElements){
			//binary restriction
			int x = rand()%255+1;
			dataSource.write((char*) &x, sizeof(int));
			counter++;
		}
		dataSource.close();*/

		ifstream dataSource2;
		dataSource2.open("../dataInt.bin", ios::binary | ios::in);
		if(dataSource2){
			int y;
			do {
				dataSource2.read((char*) &y, sizeof(y));
				//cout <<y<<" ";
			}while(dataSource2.peek() != EOF);
			//cout <<"\n ";

			//Getting the length of the file
			dataSource2.seekg(0, ios::end);
			fileLength = dataSource2.tellg();

			//returning back to the beginning of the file
			dataSource2.seekg(0, ios::beg);

			//Create a buffer equal to the length of the file i.e ten integers, the length is 40
			char *buffer = new char[fileLength];

			//Load the file's content to the buffer
			//Binary data loaded
			dataSource2.read(buffer, fileLength);
			return buffer;
		}
		else{
			char szTmp[1024];
			getcwd(szTmp, sizeof(szTmp));
			cout<<"problem with opening the binary file. | "<<szTmp<<"\n";
			return NULL;
		}
	}//End of get data

	//Current code only handles two slave nodes
	char ** partitionBinaryData(char *buffer){
		char **partitionsArray = new char *[n];
		//Partitioning
		char *shardedBuf1 = new char[shardsLength1];
		char *shardedBuf2 = new char[shardsLength2];
		int j = 0;
		int k = 0;
		int fileLength = numberOfElements*sizeOfElement;
		for(int i=0; i<fileLength-3; i+=4){
			//calculating the index of the integer (4 bytes) not a byte
			int tmpIndex = i/4;
			if(tmpIndex%n!=0){
				shardedBuf1[j] = buffer[i];
				shardedBuf1[j+1] = buffer[i+1];
				shardedBuf1[j+2] = buffer[i+2];
				shardedBuf1[j+3] = buffer[i+3];
				j+=4;
			}
			else{
				shardedBuf2[k] = buffer[i];
				shardedBuf2[k+1] = buffer[i+1];
				shardedBuf2[k+2] = buffer[i+2];
				shardedBuf2[k+3] = buffer[i+3];
				k+=4;
			}
		}
		partitionsArray[0] = shardedBuf1;
		partitionsArray[1] = shardedBuf2;
		return partitionsArray;

	}//End of partition code

	//Convert a binary array to an array of integers
	int * serialize(char *binaryData, int arrLength){
		int *intData = new int[arrLength/sizeOfElement];
		int k=0;
		for(int i=0; i<arrLength-3; i+=4)
		{
			int theInt;
			theInt = (theInt << 8) + (unsigned char)binaryData[i+3];
			theInt = (theInt << 8) + (unsigned char)binaryData[i+2];
			theInt = (theInt << 8) + (unsigned char)binaryData[i+1];
			theInt = (theInt << 8) + (unsigned char)binaryData[i];
			intData[k] = theInt;
			k++;
		}
		return intData;
	}

	long sumOfIntArray(int *intData, int arrLength){
		long sum=0;
		for(int i=0; i<arrLength; i++){
			//cout<<intData[i]<<", ";
			sum = sum + (unsigned int)intData[i];
		}
		//cout<<"\n ";
		return sum;
	}

	unsigned char * serSquareDeser(char * bData, int arrLength){
		unsigned char *binarySquares = new unsigned char[arrLength];
		for(int i=0; i<arrLength-3; i+=4)
		{
			int theInt;
			theInt = (theInt << 8) + (unsigned char)bData[i+3];
			theInt = (theInt << 8) + (unsigned char)bData[i+2];
			theInt = (theInt << 8) + (unsigned char)bData[i+1];
			theInt = (theInt << 8) + (unsigned char)bData[i];
			int sqr = theInt*theInt;
			binarySquares[i+3] = (unsigned char)(sqr >> 24) & 0xFF;
			binarySquares[i+2] = (unsigned char)(sqr >> 16) & 0xFF;
			binarySquares[i+1] = (unsigned char)(sqr >> 8) & 0xFF;
			binarySquares[i] = (unsigned char) sqr & 0xFF;
		}
		return binarySquares;
	}


	////////////////////////////////////
	//Sending the data
	//void* mpiFunc(void* p)
	///////////////////////////////////
public:
	void* mpiFunc(){
		//MPI Initialization Code
		int rank, world_size;
		int tag=1;
		MPI_Init(NULL, NULL);
		// Get the number of processes
		MPI_Comm_size(MPI_COMM_WORLD, &world_size);
		// Get the rank of the process
		MPI_Comm_rank(MPI_COMM_WORLD, &rank);
		MPI_Status stat[4];
		//MPI_Request request[4];
		while(true){
			//Master Node
			if(rank ==0){
				//Getting the binary data
				char *buffer = getBinaryData();
				char **partitions = partitionBinaryData(buffer);
				long totalOfSquares = 0;
				//Sends the partitions
				//waits for the slave nodes to send the squares
				//sum the squares
				for(int i=1; i<=n; i++)
				{
					//if number of elements divided by n is a fraction. Send the last node the non-dominant array length
					if(i==n){
						MPI_Send(partitions[i-1], shardsLength2, MPI_CHAR, i, tag, MPI_COMM_WORLD);
						sent  = sent + shardsLength2;
						char *test = new char[shardsLength2];
						MPI_Recv(test, shardsLength2, MPI_CHAR, i, tag, MPI_COMM_WORLD, &stat[2]);
						int recvCount;
						MPI_Get_count(&stat[2], MPI_CHAR, &recvCount);
						received = received+(long)recvCount;
						int *intData = serialize(test, shardsLength2);
						long partitionTotal = sumOfIntArray(intData, lastPartitionCount);
						totalOfSquares = totalOfSquares + partitionTotal;
					}
					//The rest of the nodes get the dominant array size
					else{
						MPI_Send(partitions[i-1], shardsLength1, MPI_CHAR, i, tag, MPI_COMM_WORLD);
						sent  = sent + shardsLength2;
						char *test = new char[shardsLength1];
						MPI_Recv(test, shardsLength1, MPI_CHAR, i, tag, MPI_COMM_WORLD, &stat[3]);
						int recvCount;
						MPI_Get_count(&stat[3], MPI_CHAR, &recvCount);
						received = received+(long)recvCount;
						int *intData = serialize(test, shardsLength1);
						long partitionTotal = sumOfIntArray(intData, dominantCount);
						totalOfSquares = totalOfSquares + partitionTotal;
					}
				}
				//cout<<"Total of squares of all unsigned integers provided: "<< totalOfSquares <<"\n";
			}
			//last node may have a different array length (if NumberOfElements/n% !=0)
			else if(rank == n){
				slaveNode = rank;
				int dest=0;
				int source=0;
				char *msgIn = new char[shardsLength2];
				MPI_Recv(msgIn, shardsLength2, MPI_CHAR, source, tag, MPI_COMM_WORLD, &stat[0]);
				int recvCount;
				MPI_Get_count(&stat[0], MPI_CHAR, &recvCount);
				receivedByNPerSec = receivedByNPerSec+ (long)recvCount;
				unsigned char *msgOut = new unsigned char[shardsLength2];
				msgOut = serSquareDeser(msgIn, shardsLength2);
				MPI_Send(msgOut, shardsLength2, MPI_CHAR, dest, tag, MPI_COMM_WORLD);
				sentByNPerSec = sentByNPerSec+shardsLength2;
			}
			else if(rank >0 && rank < n){
				slaveNode = 1;
				int dest=0;
				int source=0;
				char *msgIn = new char[shardsLength1];
				MPI_Recv(msgIn, shardsLength1, MPI_CHAR, source, tag, MPI_COMM_WORLD, &stat[1]);
				int recvCount;
				MPI_Get_count(&stat[1], MPI_CHAR, &recvCount);
				receivedByNPerSec = receivedByNPerSec+(long)recvCount;
				unsigned char *msgOut = new unsigned char[shardsLength1];
				msgOut = serSquareDeser(msgIn, shardsLength1);
				MPI_Send(msgOut, shardsLength1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);
				sentByNPerSec = sentByNPerSec+shardsLength1;
			}
		}//End of While
		MPI_Finalize();
		return NULL;
	}//End of MPI function

};

MpiParallelOp::MpiParallelOp(){
	numberOfElements = 250000;
	sizeOfElement = sizeof(int);
	n = 2;
	int tmp = numberOfElements/n;
	int lSize = ceil((double)numberOfElements/n);
	int sSize = floor((double)numberOfElements/n);
	if(abs(tmp-lSize)< abs(tmp-sSize)){
		dominantCount = lSize;
		lastPartitionCount = sSize;
	}
	else{
		dominantCount = sSize;
		lastPartitionCount = lSize;
	}
	shardsLength1 = dominantCount*sizeOfElement;
	shardsLength2 = lastPartitionCount*sizeOfElement;
	fileLength = 0;

}

void* testFunc(void* p){
	MpiParallelOp testObj;
	testObj.mpiFunc();
	return NULL;
}


int main(int argc, char *argv[]) {
	pthread_t threadxx;
		pthread_create(&threadxx, NULL, &testFunc, NULL);
		while(true){
			sleep(1);
			if(slaveNode >= 1){
				cout << "Slave Process ("<<slaveNode<<") | Data received: "<<(long) receivedByNPerSec<<" Byte/s, Data sent: "<<(long) sentByNPerSec<<" Byte/s\n";
				sentByNPerSec = 0;
				receivedByNPerSec = 0;
			}
			else{
				cout << "Master process (0) | data sent: "<<(long) sent<<" Byte/s, data received: "<<received<<"Bytes/s\n";
				sent = 0;
				received =0;
			}

		}
		pthread_exit(NULL);
		return 0;

}

